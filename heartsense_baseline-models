import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import joblib
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV
from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from collections import Counter
from prettytable import PrettyTable
from imblearn.over_sampling import SMOTE  # Importing SMOTE

# Load dataset
try:
    raw_df = pd.read_csv('../input/heart-failure-prediction/heart.csv')
except:
    raw_df = pd.read_csv('heart.csv')

# Check class distribution
labels = ["Healthy", "Heart Disease"]
fig = px.pie(values=raw_df['HeartDisease'].value_counts(), names=labels, width=700, height=400, 
             color_discrete_sequence=["skyblue", "black"], title="Healthy vs Heart Disease")
fig.show()

# Identify numerical and categorical features
numerical_columns = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
categorical_columns = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

# Outlier detection using IQR
def IQR_method(df, n, features):
    outlier_list = []
    for column in features:
        Q1 = np.percentile(df[column], 25)
        Q3 = np.percentile(df[column], 75)
        IQR = Q3 - Q1
        outlier_step = 1.5 * IQR
        outliers = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step)].index
        outlier_list.extend(outliers)
    return list(k for k, v in Counter(outlier_list).items() if v > n)

outliers_IQR = IQR_method(raw_df, 1, numerical_columns)
df = raw_df.drop(outliers_IQR, axis=0).reset_index(drop=True)

# One-hot encoding for categorical variables
df = pd.get_dummies(df, drop_first=True)

# Train-test split
X = df.drop('HeartDisease', axis=1)
y = df['HeartDisease']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])

# Apply SMOTE for oversampling the minority class
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# Baseline models
baseline_models = {
    "Logistic Regression": LogisticRegression(solver='lbfgs', max_iter=200),
    "Random Forest": RandomForestClassifier(),
    "SVC": SVC(gamma='auto', probability=True),
    "AdaBoost": AdaBoostClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "XGBoost": XGBClassifier(),
    "CatBoost": CatBoostClassifier(verbose=0),
    "Neural Network": MLPClassifier(max_iter=10000)
}

# Hyperparameter tuning for selected models
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, None]
}

param_grid_svc = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

param_grid_xgb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 6, 10]
}

# GridSearchCV for RandomForest, SVC, and XGBoost
grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_svc = GridSearchCV(SVC(probability=True), param_grid_svc, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_xgb = GridSearchCV(XGBClassifier(), param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1)

# Table to store model scores
table = PrettyTable()
table.field_names = ["Model", "Accuracy", "Recall", "Precision", "F1 Score"]

# Train and evaluate each model
for name, model in baseline_models.items():
    # Hyperparameter optimization for specific models
    if name == "Random Forest":
        model = grid_search_rf.fit(X_train, y_train).best_estimator_
    elif name == "SVC":
        model = grid_search_svc.fit(X_train, y_train).best_estimator_
    elif name == "XGBoost":
        model = grid_search_xgb.fit(X_train, y_train).best_estimator_
    
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # Add results to the table
    table.add_row([name, round(accuracy, 4), round(recall, 4), round(precision, 4), round(f1, 4)])

# Voting Classifier (Soft Voting)
soft_voting = VotingClassifier(list(baseline_models.items()), voting='soft')
soft_voting.fit(X_train, y_train)
y_pred = soft_voting.predict(X_test)

# Calculate metrics for the ensemble model
ensemble_accuracy = accuracy_score(y_test, y_pred)
ensemble_recall = recall_score(y_test, y_pred)
ensemble_precision = precision_score(y_test, y_pred)
ensemble_f1 = f1_score(y_test, y_pred)

# Add ensemble model results to the table
table.add_row(["Soft Voting Ensemble", round(ensemble_accuracy, 4), round(ensemble_recall, 4), 
               round(ensemble_precision, 4), round(ensemble_f1, 4)])

# Print the comparison table
print("Model Comparison:")
print(table)

# Save the trained ensemble model and scaler
joblib.dump(soft_voting, "soft_voting_model.pkl")
joblib.dump(scaler, "scaler.pkl")

# Learning Curve Function
def plot_learning_curve(model, X_train, y_train, title="Learning Curves"):
    train_sizes, train_scores, validation_scores = learning_curve(
        model, X_train, y_train, cv=5, train_sizes=np.linspace(0.1, 1.0, 10), scoring="accuracy", n_jobs=-1
    )
    train_mean = np.mean(train_scores, axis=1)
    val_mean = np.mean(validation_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_std = np.std(validation_scores, axis=1)

    plt.figure(figsize=(8, 6))
    plt.plot(train_sizes, train_mean, color="b", label="Training accuracy")
    plt.plot(train_sizes, val_mean, color="r", label="Validation accuracy")
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color="b", alpha=0.2)
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color="r", alpha=0.2)
    
    plt.title(title)
    plt.xlabel("Training Size")
    plt.ylabel("Accuracy")
    plt.legend(loc="best")
    plt.grid(True)
    plt.show()

# Plot learning curve for Soft Voting Classifier
print("Learning Curve for Soft Voting Classifier:")
plot_learning_curve(soft_voting, X_train, y_train, title="Soft Voting Classifier Learning Curves")

# ROC Curve Function
def plot_roc_curve(model, X_test, y_test):
    y_prob = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    auc = roc_auc_score(y_test, y_prob)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='b', label=f'AUC = {auc:.2f}')
    plt.plot([0, 1], [0, 1], color='k', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('AUC-ROC Curve for Soft Voting')
    plt.legend(loc='best')
    plt.show()

# Plot AUC-ROC for Soft Voting
print("AUC-ROC Curve for Soft Voting:")
plot_roc_curve(soft_voting, X_test, y_test)
import joblib

import shap

# Select the RandomForest model from the ensemble
rf_model = soft_voting.named_estimators_['Random Forest']

# Initialize TreeExplainer
explainer = shap.TreeExplainer(rf_model)

# Compute SHAP values
shap_values = explainer.shap_values(X_test)

# Generate SHAP summary plot
shap.summary_plot(shap_values, X_test)

# Select and generate SHAP plots for each model in the ensemble

# Logistic Regression
logreg_model = soft_voting.named_estimators_['Logistic Regression']
logreg_explainer = shap.LinearExplainer(logreg_model, X_train)
logreg_shap_values = logreg_explainer.shap_values(X_test)
shap.summary_plot(logreg_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for Logistic Regression")
plt.show()

# SVC (Support Vector Classifier)
svc_model = soft_voting.named_estimators_['SVC']
svc_explainer = shap.KernelExplainer(svc_model.predict_proba, X_train)
svc_shap_values = svc_explainer.shap_values(X_test)
shap.summary_plot(svc_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for SVC")
plt.show()

# AdaBoost
adaboost_model = soft_voting.named_estimators_['AdaBoost']
adaboost_explainer = shap.TreeExplainer(adaboost_model)
adaboost_shap_values = adaboost_explainer.shap_values(X_test)
shap.summary_plot(adaboost_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for AdaBoost")
plt.show()

# Gradient Boosting
gb_model = soft_voting.named_estimators_['Gradient Boosting']
gb_explainer = shap.TreeExplainer(gb_model)
gb_shap_values = gb_explainer.shap_values(X_test)
shap.summary_plot(gb_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for Gradient Boosting")
plt.show()

# XGBoost
xgb_model = soft_voting.named_estimators_['XGBoost']
xgb_explainer = shap.TreeExplainer(xgb_model)
xgb_shap_values = xgb_explainer.shap_values(X_test)
shap.summary_plot(xgb_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for XGBoost")
plt.show()

# CatBoost
catboost_model = soft_voting.named_estimators_['CatBoost']
catboost_explainer = shap.TreeExplainer(catboost_model)
catboost_shap_values = catboost_explainer.shap_values(X_test)
shap.summary_plot(catboost_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for CatBoost")
plt.show()

# Neural Network
nn_model = soft_voting.named_estimators_['Neural Network']
nn_explainer = shap.DeepExplainer(nn_model, X_train)
nn_shap_values = nn_explainer.shap_values(X_test)
shap.summary_plot(nn_shap_values, X_test, plot_type="bar")
plt.title("SHAP Summary Plot for Neural Network")
plt.show()


